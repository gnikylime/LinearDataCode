{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Data Lab 9\n",
    "\n",
    "Original lab written by: Emily J. King\n",
    "\n",
    "Goals: Calculate if a set of vectors is linearly independent or if a vector is in a spans. Calculate an orthonormal basis given a basis. Implement orthogonal projections onto subspaces and relate their output to direct sums of subspaces. Use the output of certain change of bases (e.g., discrete cosine transformation) or change of coordinates to characterize data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from numpy.linalg import matrix_rank as rank # for determining dimension of span\n",
    "from scipy.fftpack import dct # for discrete cosine transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 1: Dimension and linear independence\n",
    "\n",
    "Create four random vectors x, y, z, w in R^7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.rand(7)\n",
    "y=np.random.rand(7)\n",
    "z=np.random.rand(7)\n",
    "w=np.random.rand(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly chosen vectors in R^n are typically linearly independent, as long as the number of vectors is less than or equal to n.  (Without getting into the technical details, if you ask a computer for a set of <= n random vectors in R^n, one can basically guarantee that they will be linearly independent.)\n",
    "\n",
    "Let's check that by testing the dimension of their span by computing the rank of the matrix with x, y, z, and w as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank(np.column_stack((x,y,z,w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got 4 as the rank, which means the 4 vectors are indeed linearly independent.  Another way of saying the same thing is that x, y, z, and w form a basis for their span.\n",
    "\n",
    "Now let's compute the dimension of the span of x, y, z, w, and x+y+z+w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank(np.column_stack((x,y,z,w,x+y+z+w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's still 4, even though there are 5 vectors.  This tells us that x, y, z, w, and x+y+z+w are linearly dependent.  But this makes sense as we can literally see how the fifth vector is a linear combination of the other four.\n",
    "\n",
    "More generally, we can test if a vector v is in the span of vectors u_1, u_2, ..., u_n by comparing the dimensions of the spans of (u_1, u_2, ..., u_n) and (u_1, u_2, ..., u_n, v).  If the two numbers are equal, then v was already in the span of the (u_1, u_2, ..., u_n) and didn't \"add\" any new information.\n",
    "\n",
    "Let's add four more random vectors to the original set and test the dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank(np.column_stack((x,y,z,w,np.random.rand(7),np.random.rand(7),np.random.rand(7),np.random.rand(7))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened?  Even though there are 8 random vectors, the vectors are in the 7-dimensional space R^7.  Thus, they cannot span a space of dimension greater than 7.  In particular, the vectors must be linearly dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 2: Orthonormal bases and orthogonal projections\n",
    "\n",
    "We know that x, y, z, and w from above form a basis for their span.  How could we generate an orthonormal basis with the same span?  There are many ways to do that on a computer.  We will use the singular value decomposition (SVD) because in Module 11 we will learn some of the theory behind the SVD (as well as teasing another application in Module 9).\n",
    "\n",
    "Assume that A is a matrix with m columns in R^n spanning a d-dimensional subspace. For now, just accept the SVD as a magic wand from Matica that takes A and returns a set of three matrices.  The first matrix it returns (typically labeled U) has as its first d column an orthonormal basis for the span of the columns of A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = np.linalg.svd(np.column_stack((x,y,z,w)))[0]\n",
    "xyzwONB=U[:,0:4]\n",
    "xyzwONB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test that the columns of xyzwONB are indeed orthonormal.  Instead of one-by-one computing u_i^T u_j for each pair of columns, we can compute one matrix multiplication to get all of the inner products.  This is called the gram matrix or grammian of the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyzwONB.T@xyzwONB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The (i,j) entry of the matrix above is the inner product of the ith column of xyzwONB with the jth columns of xyzwONB.  Up to floating point arithmetic, the above matrix is the 4x4 identity matrix.  This means that the norm squared of each vector (i.e., the inner product with itself) is 1 and the inner product of any two different vectors is 0. So, this set is definitely orthonormal.  This also means it is linearly independent.\n",
    "\n",
    "Now let's test to see if the columns of xyzwONB span the same space as x, y, z, and w.  Since the (four) columns of xyzwONB are orthonormal and thus linearly independent, they span a 4-dimensional space.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank(xyzwONB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if the dimension of the span of the columns of xyzwONB and x, y, z, w is 4, we know that x, y, z, w haven't added any \"new information\", i.e., are in the span of the columns of xyzwONB.  Going other way, if the dimension of the span of the columns of xyzwONB and x, y, z, w is 4, we know the columns of xyzwONB don't add any new information to the span of x, y, z, w, meaning the two sets have the same span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank(np.column_stack((xyzwONB,x,y,z,w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing, if you have a set of vectors, you can put them as columns in a matrix A.  The rank of that matrix A is the dimension of the span.  If additionally, you want an orthonormal basis for the span of the vectors, take the first rank(A) columns of the first matrix output by SVD(A).\n",
    "\n",
    "(Actually, there is a way to determine rank using SVD, but we're trying to keep things relatively simple.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end this section by noting that once you have the orthonormal basis for a subspace as the columns of a matrix, it is very easy to compute the orthogonal project.  \n",
    "\n",
    "Note that the order of matrix multiplication is the opposite as the gram matrix calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyzwONB@xyzwONB.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 7x7 orthogonal projection matrix.  If you multiply any vector in R^7 on the left by it, you find the closest element to that vector in the 4-dimensional subspace that is the span of x, y, z, w."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 3: Discrete cosine transformation\n",
    "\n",
    "Let's begin by generating the DCT-II basis for R^5 as seen in lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=dct(np.eye(5),norm='ortho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of D are the DCT-II basis, which is an orthonormal basis.  Let's remind ourselves of what the vectors look like by plotting them as functions with straight lines between the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5\n",
    "k=np.linspace(0,n-1,n)\n",
    "cols=['k','b','g','y','r']\n",
    "for j in range(0,n):\n",
    "    plt.plot(k,D[:,j],'o-',color=cols[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the DCT of a vector in R^5 is the same as multiplying the vector on the left by the transpose of D, which is the same as mapping the vector to the sequence of inner products with the columns of D.\n",
    "\n",
    "Let's compute the DCT of the first DCT basis vector, i.e., the constant vector plotted in black above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct(D[:,0],norm='ortho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a 1 followed by four 0's.  This is because the first DCT basis vector has unit norm and is orthogonal to all of the other DCT basis vectors.  Another way to state things: The first basis vector is equal to the linear combination of itself and none of the other basis vectors.\n",
    "\n",
    "We get a similar result with the middle basis vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct(D[:,2],norm='ortho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get (up to floating point arithmetic) two 0s, one 1, and two more 0s.\n",
    "\n",
    "Now let's plot and then compute the DCT of a linear combination of these two basis vectors, i.e., -1 times the first one plus 2 times the middle one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k,-D[:,0]+2*D[:,2],'o-',color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape is very similar to the shape of the middle basis vector but now the range of values is twice as big and the vector now has more negative values.  Adding and substracting the first basis vector just affects the average value and not the shape.  Now let's compute the DCT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct(-D[:,0]+2*D[:,2],norm='ortho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get, up to floating point arithmetic, (-1,0, 2, 0, 0), which should make sense.\n",
    "\n",
    "Play around with other linear combinations of other basis vectors and discuss.\n",
    "\n",
    "Now let's take a vector which is not as \"obviously\" a linear combination of the basis vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.array([1,-1,1,-1,1])\n",
    "plt.plot(k,b,'o-',color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it is a very \"bouncy\" vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct(b,norm='ortho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the largest value from the DCT was the last one.  This should make sense, as the last basis vector is the \"bounciest\".\n",
    "\n",
    "Now, we will make a bit more complicated vector.  This one will take values from a cosine function that has a frequency strictly between the cosine functions used to make the third and fourth basis vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=2.5\n",
    "c=np.sqrt(2/n)*np.cos(np.pi*(k+(1/2))*j/n)\n",
    "plt.plot(k,c,'o-',color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula above for j=0, 1, 2, 3, 4 yields the DCT-II basis vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct(c,norm='ortho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the third and fourth coefficients of the DCT are much larger in absolute value than the others.  This shows the \"bounciness\" between a mix of the frequencies.  They aren't prefectly equal due to some normalization issues with DCT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generate three random vecotrs r, s, t in R^1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Verify that the dimension of the span of r, s, t is three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate an orthonormal basis for the span of r, s, t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a matrix which performs an orthogonal projection from R^1000 to the span of r, s, t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Compute and plot the DCT of r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Discuss the output of 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
